{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bayesian-crowd.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GJHKEpPQox8u"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MhPrOhalcgQ",
        "outputId": "0bd16c8c-4e02-48b8-c589-7f1569b85236"
      },
      "source": [
        "# clone model repository\n",
        "!git clone https://github.com/ZhihengCV/Bayesian-Crowd-Counting.git\n",
        "\n",
        "# clone custom repository\n",
        "!git clone https://github.com/InnovationLab-Top/CrowdCounting.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bayesian-Crowd-Counting'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 168 (delta 8), reused 2 (delta 0), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (168/168), 1.46 MiB | 3.76 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n",
            "Cloning into 'CrowdCounting'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 18 (delta 4), reused 17 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n",
            "Checking out files: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_JENq2iIyDR",
        "outputId": "3abdca0f-e6e4-44c6-d9df-32ba6379ab7b"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJHKEpPQox8u"
      },
      "source": [
        "# JHU-CROWD++\n",
        "\n",
        "The JHU Crowd v2.0 dataset is available at http://www.crowd-counting.com/#download\n",
        "You can make a shortcut of the dataset in your google drive and change the JHU_PATH variable to it in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3pAWkK4h5Wl"
      },
      "source": [
        "# change JHU_PATH to your drive shortcut of JHU dataset \n",
        "JHU_PATH = '/content/drive/MyDrive/Colab_Notebooks/Crowd_detection/jhu_crowd_v2.0.zip'\n",
        "\n",
        "# unzip JHU-CROWD++\n",
        "!unzip -q {JHU_PATH} -d /content/Bayesian-Crowd-Counting/datasets/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2zGz5boLwR"
      },
      "source": [
        "# make directories for training, test and the output of the preprocessing\n",
        "!mkdir /content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/Train\n",
        "!mkdir /content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/Test\n",
        "!mkdir /content/Bayesian-Crowd-Counting/preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFeBC7Bqbne"
      },
      "source": [
        "# move TRAIN_SIZE random images and relative labels to the Train folder\n",
        "import glob\n",
        "import random as rnd\n",
        "from shutil import move\n",
        "\n",
        "TRAIN_SIZE = 1000\n",
        "TEST_SIZE = 1   # there must be at least one image in the test folder\n",
        "\n",
        "DST_TRAIN = '/content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/Train/'\n",
        "SRC_TRAIN = '/content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/train/images/'\n",
        "paths_train = glob.glob(SRC_TRAIN + '*.jpg')\n",
        "rnd.shuffle(paths_train)\n",
        "for i, name in enumerate(paths_train):\n",
        "  move(name, DST_TRAIN)\n",
        "  move(name.replace('images/', 'gt/').replace('.jpg', '.txt'), DST_TRAIN)\n",
        "  if i == (TRAIN_SIZE - 1):\n",
        "    break\n",
        "\n",
        "# move TEST_SIZE random images and relative labels to the Test folder\n",
        "DST_TEST = '/content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/Test/'\n",
        "SRC_TEST = '/content/Bayesian-Crowd-Counting/datasets/jhu_crowd_v2.0/test/images/'\n",
        "paths_test = glob.glob(SRC_TEST + '*.jpg')\n",
        "rnd.shuffle(paths_test)\n",
        "for i, name in enumerate(paths_test):\n",
        "  move(name, DST_TEST)\n",
        "  move(name.replace('images/', 'gt/').replace('.jpg', '.txt'), DST_TEST)\n",
        "  if i == (TEST_SIZE - 1):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGwBQOxvuKYp"
      },
      "source": [
        "# create .txt files with the paths of images in the training set\n",
        "paths_img_train = glob.glob(DST_TRAIN + '*.jpg')\n",
        "with open('/content/train.txt', 'w') as f:\n",
        "  for path in paths_img_train:\n",
        "    f.write(path+\"\\n\")\n",
        "\n",
        "# choose validation size and move VAL_SIZE image paths from train.txt to val.txt\n",
        "VAL_SIZE = 100\n",
        "with open('/content/train.txt', 'r') as f1:\n",
        "  lines = f1.readlines()\n",
        "with open('/content/train.txt', 'w') as f1:\n",
        "  for line in lines[VAL_SIZE:]:\n",
        "    f1.write(line)\n",
        "with open('/content/val.txt', 'w') as f2:\n",
        "  for line in lines[:VAL_SIZE]:\n",
        "    f2.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-K9e4xixAeb"
      },
      "source": [
        "# import custom preprocess_txt.py necessary for the preprocessing of images with .txt labels\n",
        "!cp /content/CrowdCounting/preprocess_txt.py /content/Bayesian-Crowd-Counting/"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm1e02WRwRRK",
        "outputId": "c75b0444-0b54-487f-925b-8b5c0fc1f2aa"
      },
      "source": [
        "# run preprocessing\n",
        "!python /content/Bayesian-Crowd-Counting/preprocess_txt.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img errata 1002.jpg\n",
            "tcmalloc: large alloc 1911267328 bytes == 0x55d999b92000 @  0x7f6f8edf71e7 0x7f6f8c97746e 0x7f6f8c9c7c7b 0x7f6f8c9c7d18 0x7f6f8ca83d79 0x7f6f8ca86add 0x7f6f8cbae9ba 0x7f6f8cbaf516 0x55d98b361c52 0x55d98b3d54d9 0x55d98b362afa 0x55d98b3d0915 0x55d98b3cf9ee 0x55d98b3cf6f3 0x55d98b4994c2 0x55d98b49983d 0x55d98b4996e6 0x55d98b471163 0x55d98b470e0c 0x7f6f8dbe1bf7 0x55d98b470cea\n",
            "tcmalloc: large alloc 1911267328 bytes == 0x55da0ba4c000 @  0x7f6f8edf71e7 0x7f6f8c97746e 0x7f6f8c9c7c7b 0x7f6f8c9c7d18 0x7f6f8ca83d79 0x7f6f8ca86e4c 0x7f6f8cba5e7f 0x7f6f8cbabfb5 0x7f6f8cbade3d 0x7f6f8cbaf516 0x55d98b362720 0x55d98b3622f9 0x7f6f8ca8e0db 0x55d98b44b0b2 0x55d98b3d162d 0x55d98b362afa 0x55d98b3d0915 0x55d98b3cf9ee 0x55d98b3cf6f3 0x55d98b4994c2 0x55d98b49983d 0x55d98b4996e6 0x55d98b471163 0x55d98b470e0c 0x7f6f8dbe1bf7 0x55d98b470cea\n",
            "tcmalloc: large alloc 1911267328 bytes == 0x55d999b92000 @  0x7f6f8edf71e7 0x7f6f8c97746e 0x7f6f8c9c7c7b 0x7f6f8c9c7d18 0x7f6f8ca83d79 0x7f6f8ca86e4c 0x7f6f8cba5e7f 0x7f6f8cbabfb5 0x7f6f8cbade3d 0x7f6f8cbaf516 0x55d98b362720 0x55d98b3622f9 0x7f6f8ca8e00b 0x55d98b449d31 0x55d98b3d1320 0x55d98b362afa 0x55d98b3d0915 0x55d98b3cf9ee 0x55d98b3cf6f3 0x55d98b4994c2 0x55d98b49983d 0x55d98b4996e6 0x55d98b471163 0x55d98b470e0c 0x7f6f8dbe1bf7 0x55d98b470cea\n",
            "tcmalloc: large alloc 1911267328 bytes == 0x55da0ba4c000 @  0x7f6f8edf71e7 0x7f6f8c97746e 0x7f6f8c9c7c7b 0x7f6f8c9c7d18 0x7f6f8cbac40f 0x7f6f8cbade3d 0x7f6f8cbaf516 0x55d98b361c52 0x55d98b3d54d9 0x55d98b362afa 0x55d98b3d0915 0x55d98b3cf9ee 0x55d98b3cf6f3 0x55d98b4994c2 0x55d98b49983d 0x55d98b4996e6 0x55d98b471163 0x55d98b470e0c 0x7f6f8dbe1bf7 0x55d98b470cea\n",
            "tcmalloc: large alloc 1911267328 bytes == 0x55d999b92000 @  0x7f6f8edf71e7 0x7f6f8c97746e 0x7f6f8c9c7c7b 0x7f6f8c9c7d18 0x7f6f8cbac287 0x7f6f8cbade3d 0x7f6f8cbaf516 0x55d98b361c52 0x55d98b3d54d9 0x55d98b362afa 0x55d98b3d0915 0x55d98b3cf9ee 0x55d98b3cf6f3 0x55d98b4994c2 0x55d98b49983d 0x55d98b4996e6 0x55d98b471163 0x55d98b470e0c 0x7f6f8dbe1bf7 0x55d98b470cea\n",
            "img errata 0746.jpg\n",
            "img errata 1247.jpg\n",
            "img errata 3446.jpg\n",
            "img errata 1707.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJR8T1wQotM"
      },
      "source": [
        "# Make directory for weights save, copy shanghai A weights\n",
        "!mkdir /content/Bayesian-Crowd-Counting/workdir\n",
        "!cp /content/CrowdCounting/best_model_sha.pth /content/Bayesian-Crowd-Counting/best_model.pth\n",
        "\n",
        "# define variables for training\n",
        "TRAIN_PATH = \"/content/Bayesian-Crowd-Counting/train.py\"\n",
        "DATA_PATH = '/content/Bayesian-Crowd-Counting/preprocessed'\n",
        "SAVE_PATH = '/content/Bayesian-Crowd-Counting/workdir'\n",
        "WEIGHTS_PATH = '/content/Bayesian-Crowd-Counting/best_model.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6pfAhWtUJlX"
      },
      "source": [
        "# run training\n",
        "!python {TRAIN_PATH} --data-dir {DATA_PATH} --save-dir {SAVE_PATH} --resume {WEIGHTS_PATH} --val-start 10 --max-epoch 100 --batch-size 16 --num-workers 2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqZ48ZEpqJq_"
      },
      "source": [
        "# Test on custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-tVhfAJI6pf"
      },
      "source": [
        "# copy best weights in model directory\n",
        "!cp /content/CrowdCounting/best_model.pth /content/Bayesian-Crowd-Counting/best_model.pth\n",
        "# create directory for video frames\n",
        "!mkdir /content/Bayesian-Crowd-Counting/datasets/frames\n",
        "# create directory for predictions\n",
        "!mkdir /content/plot_predictions"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BrZtIM1blS"
      },
      "source": [
        "The custom_crowd.py and test_custom.py files are necessary because it enables the use of images without labels during the test phase. In the train phase the program will instead use the standard crowd.py file. Also the test_custom file plots images and saves them in the correct directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MimHpko748Tn"
      },
      "source": [
        "# copy custom test.py and crowd.py in model directory\n",
        "!cp /content/CrowdCounting/crowd_custom.py /content/Bayesian-Crowd-Counting/datasets/\n",
        "!cp /content/CrowdCounting/test_custom.py /content/Bayesian-Crowd-Counting/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EH2o_sCFASf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2122bd6-1260-4eb6-c43c-7d642aaa0e1b"
      },
      "source": [
        "# delete all elements in frames directory\n",
        "!rm /content/Bayesian-Crowd-Counting/datasets/frames/*\n",
        "# frames capture from video\n",
        "import cv2\n",
        "import os\n",
        "SOURCE_VIDEO = '/content/CrowdCounting/demo_video.mp4'\n",
        "SKIP = 30\n",
        "vidcap = cv2.VideoCapture(SOURCE_VIDEO)\n",
        "success, image = vidcap.read()\n",
        "count = 0\n",
        "while success:\n",
        "  cv2.imwrite(f\"/content/Bayesian-Crowd-Counting/datasets/frames/{str(count).zfill(5)}.jpg\", image)     # save frame as JPEG file      \n",
        "  success, image = vidcap.read()\n",
        "  count += SKIP\n",
        "  vidcap.set(cv2.CAP_PROP_POS_FRAMES, count)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/Bayesian-Crowd-Counting/datasets/frames/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY7TL2ceYRRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e600e4-ad1a-4156-9683-1e5cc0a5965d"
      },
      "source": [
        "# empty the predictions' folder\n",
        "!rm /content/plot_predictions/*"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/plot_predictions/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtJVwSoOHdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35f22c9-4d7f-4b3f-c251-88612d76a8e1"
      },
      "source": [
        "# test model on video\n",
        "!python /content/Bayesian-Crowd-Counting/test_custom.py --data-dir /content/Bayesian-Crowd-Counting/datasets/frames/ --save-dir /content/Bayesian-Crowd-Counting/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:03<00:00, 172MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3825: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Frame: ('00000',), Predicted count: 1416.692138671875\n",
            "Frame: ('00030',), Predicted count: 1365.9786376953125\n",
            "Frame: ('00060',), Predicted count: 1481.376220703125\n",
            "Frame: ('00090',), Predicted count: 1563.2957763671875\n",
            "Frame: ('00120',), Predicted count: 1888.9830322265625\n",
            "Frame: ('00150',), Predicted count: 1797.0126953125\n",
            "Frame: ('00180',), Predicted count: 1729.546142578125\n",
            "Frame: ('00210',), Predicted count: 2210.97607421875\n",
            "Frame: ('00240',), Predicted count: 1928.1640625\n",
            "Frame: ('00270',), Predicted count: 2306.31201171875\n",
            "Frame: ('00300',), Predicted count: 2430.41455078125\n",
            "Frame: ('00330',), Predicted count: 2113.501953125\n",
            "Frame: ('00360',), Predicted count: 2365.404296875\n",
            "Frame: ('00390',), Predicted count: 2417.865966796875\n",
            "Frame: ('00420',), Predicted count: 2077.275390625\n",
            "Frame: ('00450',), Predicted count: 2339.2626953125\n",
            "Frame: ('00480',), Predicted count: 2394.619140625\n",
            "Frame: ('00510',), Predicted count: 2024.064208984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDJYFLUO7rSo"
      },
      "source": [
        "# move number of people vs frames plot from plot_predictions to /content\n",
        "!mv /content/plot_predictions/plot_preds-frames.jpg /content/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsWq-KDKTOGr"
      },
      "source": [
        "# create gif from frames\n",
        "import imageio\n",
        "\n",
        "png_dir = '/content/plot_predictions/'\n",
        "images = []\n",
        "for file_name in sorted(os.listdir(png_dir)):\n",
        "    if file_name.endswith('.jpg'):\n",
        "        file_path = os.path.join(png_dir, file_name)\n",
        "        images.append(imageio.imread(file_path))\n",
        "imageio.mimsave('/content/plot_predictions/movie_slow.gif', images, fps=3)"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}